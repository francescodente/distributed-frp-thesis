\chapter{Background}
\label{chap:background}

This chapter gives an high level overview of the concepts, paradigms, and frameworks that were used as references throughout the development of this thesis.

\section{Functional programming}
\label{sec:fp}

\textit{Functional Programming} is a programming paradigm in which computation is expressed as a transformation of inputs into outputs using functions and function composition.
%
Here, functions are to be intended in the \textit{mathematical} sense of the term, meaning that they are just mappings from elements of their domain to elements of their co-domain.

\subsection{Functional programming concepts}

This section illustrates some of the key concepts on which functional programming is based upon and that are key when working in a functional style.

\paragraph{Purity}

The mathematical definition of a function can be adapted to the context of computer programming, in which mathematical functions are referred to as \textbf{pure functions}.
%
To be pure, a function must satisfy the following properties:
%
\begin{itemize}
    \item given the same arguments, it always returns the same value, or in other words, its output depends solely on its arguments;
    \item it must produce no observable side effects (e.g., mutate global shared state, send data over output streams, etc).
\end{itemize}

\paragraph{Referential transparency}

A sub-expression (i.e., the application of a function) is said to be \textit{referentially transparent} if it can be safely substituted with its final value without changing the overall semantics of the complete expression that contains it.
%
This is a direct consequence of function purity, since a pure function's only observable effect is the value it returns for its given arguments and that value is consistent over time.
%
Due to this fact, referential transparency and purity are often used (erroneously) as synonyms.
%
While it is true that purity implies referential transparency, the opposite is not, in general.

\paragraph{Evaluation order strategies}

Functional languages typically support different ways to evaluate arguments as they are passed to functions.
%
There are three main approaches:
%
\begin{itemize}
    \item \textit{call-by-value}: arguments are evaluated before the function application;
    \item \textit{call-by-name}: arguments are evaluated each time they're value is required inside the body of the function;
    \item \textit{call-by-need}: also referred to as \textit{lazy} evaluation, arguments are evaluated once the first time their value is needed inside the body of the function.
\end{itemize}

\paragraph{Immutability}

One of the consequences of purity when writing code in a functional style is that programs are not allowed to have any global state that is shared among their sub-components.
%
This also means that the data structures to be used must be designed accordingly and should therefore be \textit{immutable}, allowing state changes only via creating new versions of the same data structure.
%
This is typically not a problem, since complex data structures (e.g., collections like lists, sets, maps, \dots) are optimized to reuse as much as possible when creating copies of themselves.

\paragraph{Higher order functions}

Functional programming proposes the idea of \textit{functions as first-class citizens}, indicating that functions can also be considered values and be passed around just like traditional values.
%
Therefore a function can take functions as arguments or return functions as outputs, in which case is called an \textit{higher order function}.

\section{Scala 3}

Scala is a programming language built on top of the Java Virtual Machine (JVM), with support for both the \textit{object-oriented} and the \textit{functional} paradigms \cite{10.1145/2591013}, effectively making it a \textit{multi-paradigm language}.
%
It is a pure object-oriented language, in fact everything is an \textit{object} and objects are defined through \textit{classes} and \textit{traits}.
%
It is a functional language, because it supports the idea of functions as values and allows higher order functions to be defined \cite{scala-lang-spec}.

The main features of Scala are:
%
\begin{itemize}
    \item support for both OOP and FP;
    \item seamless integration with the Java ecosystem and the JVM;
    \item powerful static type system;
    \item flexible syntax that makes it a scalable language;
\end{itemize}

The most recent version of Scala (at the time of writing) is Scala 3 \cite{scala3-reference}, which is the version that has been used during development.
%
Scala 3 introduces several new constructs and improvements over its predecessor \cite{new-in-scala-3}, that were considered to be necessary to streamline the development process and allow for a concise and conveying syntax.
%
The most relevant that were also used for this project can be summarized as follows:
%
\begin{itemize}
    \item \textbf{optional braces} introduce the ability to use a python-like syntax that controls scopes through indentation;
    \item \textbf{enumerations} improve on the traditional way of defining \textit{algebraic data types} (see \Cref{sec:enums}) that required the use of \texttt{sealed trait}s;
    \item \textbf{improved contextual abstractions} replace the use of the old \texttt{implicit}s with new constructs that better convey the developer's intent, in particular:
    \begin{itemize}
        \item \texttt{using} clauses allow methods to abstract over information that is available in the calling context and that should be passed implicitly (see \Cref{sec:given-using});
        \item \texttt{given} instances define canonical values for types that can be passed implicitly (see \Cref{sec:given-using}) and are typically used to define \textit{type class instances};
        \item \texttt{extension} methods allow developers to attach methods to types after their definition (see \Cref{sec:extension-methods});
        \item implicit conversions let the compiler view a type as another and perform conversions without explicit casting;
        \item context functions define types of functions that only take context parameters (see \Cref{sec:context-functions});
    \end{itemize}
\end{itemize}

The following sections give more details on these constructs.

\subsection{Enumerations and algebraic data types}
\label{sec:enums}

An algebraic data type (ADT) is a structured type defined as a composition of other types, which can in turn be other ADTs or atomic types.
%
ADTs can belong to one of these categories:
%
\begin{itemize}
    \item \textbf{Product Types} (also known as \textit{records}): defined as the cartesian product of its composing types;
    \item \textbf{Sum Types} (also known as \textit{discriminated unions}): defined as the union of its composing types.
\end{itemize}
%
As an example, let's consider modeling a binary tree.
%
A binary tree can be represented as an ADT through a sum type (\texttt{Tree}), which is a discriminated union of these product types:
%
\begin{itemize}
    \item \texttt{Leaf(x)}, where \texttt{x} is the value contained in the leaf itself;
    \item \texttt{Node(x, left, right)} where x is the value contained in the node itself, and \texttt{left} and \texttt{right} are respectively the left and right subtrees.
\end{itemize}
%
This ADT indicates that a binary tree is either a \textit{leaf}, in which case it only stores the value it contains, or a \textit{node}, in which case it stores its value a the left and right subtrees.
%
Note that this is a recursive definition, since \texttt{left} and \texttt{right} are also of type \texttt{Tree}.

In Scala 2, an ADT could be defined using \texttt{sealed trait}s (to represent sum types) in combination with \texttt{case class}es (modeling product types).
%
Note the use of the \texttt{sealed} keyword, which guarantees that a trait decorated with this modifier will not be extended in other source files other than the one where the trait is declared.
%
This is fundamental, since a discriminated union should not be open to extension and allow only its composing types to be used.
%
In addition, \texttt{case classes} are a perfect candidate to represent product types due to their structure (resembling that of records) and can be used seamlessly with \textit{pattern matching}.

In Scala 2, the binary tree example would be implemented as follows:
%
\begin{lstlisting}[frame=single, language=scala]
sealed trait Tree[T]
case class Leaf[T](x: T) extends Tree[T]
case class Node[T](x: T, left: Tree[T], right: Tree[T]) extends Tree[T]
\end{lstlisting}

Scala 3 takes an approach to ADTs that better conveys the intent of the developer, offering a structure that is specifically designed to represent discriminated unions.
%
The new version introduces the \texttt{enum} keyword, which smooths out the process of defining discriminated unions.
%
The Scala 3 version of the binary tree example becomes
%
\begin{lstlisting}[frame=single, language=scala]
enum Tree[T]:
  case Leaf(x: T)
  case Node(x: T, left: Tree[T], right: Tree[T])
\end{lstlisting}
%
which is more succinct and avoids the boilerplate required by its predecessor.

Finally, both approaches are well suited to be used with pattern matching (although only Scala 3 is shown here).
%
This example show the implementation of a method that converts a binary tree to a string, by using \textit{preorder traversal}.
%
\begin{lstlisting}[frame=single, language=scala]
import Tree._

def stringify[T](tree: Tree[T]): String = tree match
  case Leaf(x) => x.toString
  case Node(x, l, r) => s"$x[${stringify(l)},${stringify(r)}]"

val aTree = Node(
  1,
  Node(
    2,
    Leaf(3),
    Leaf(4)
  ),
  Leaf(5)
)

println(stringify(aTree)) // 1[2[3,4],5]
\end{lstlisting}

\subsection{Using clauses and given instances}
\label{sec:given-using}

The \texttt{using} and \texttt{given} keywords were introduced in Scala 3 as a replacement for the \texttt{implicit} keyword when passing \textit{context parameters} and when defining \textit{canonical values}.
%
Before Scala 3, in fact, the \texttt{implicit} mechanism lacked on clarity of intent, since the keyword was also used to define extension methods (see \Cref{sec:extension-methods}) and implicit conversions.

The following snippet shows how \texttt{implicit}s worked before Scala 3.
%
First, a developer would need a method accepting a parameter \texttt{implicit}ly.
%
Here, the \texttt{printBoth()} method accepts a \texttt{printer} argument that should be inferred from the caller context and not be passed explicitly.
%
\begin{lstlisting}[frame=single, language=scala]
trait Printer {
  def print(x: Any): Unit
}

def printBoth(x: Any, y: Any)(implicit printer: Printer): Unit = {
  printer.print(x)
  printer.print(y)
}
\end{lstlisting}

Next, when calling the \texttt{printBoth()} method, Scala tries to synthesize an appropriate value of type \texttt{Printer} that is marked as \texttt{implicit} in the calling scope:
%
\begin{lstlisting}[frame=single, language=scala]
implicit val printer: Printer = x => println(x)

// The following lines are equivalent.
printBoth("A", "B")
printBoth("A", "B")(printer)
\end{lstlisting}
%
Note that the \texttt{printer} value is declared using the \texttt{implicit} keyword, marking it as suitable to be passed implicitly.

As stated at the beginning of this section, Scala 3 replaces the \texttt{implicit} keyword with \texttt{using} and \texttt{given}.
%
Other than that, not much changes in the structure of the previous code:
%
\begin{lstlisting}[frame=single, language=scala]
trait Printer:
  def print(x: Any): Unit

def printBoth(x: Any, y: Any)(using printer: Printer): Unit =
  printer.print(x)
  printer.print(y)

...

given printer: Printer = x => println(x)

// The following lines are equivalent.
printBoth("A", "B")
printBoth("A", "B")(using printer)
\end{lstlisting}

Note that, just like \texttt{implicit} parameters, \texttt{using} parameters are available as \texttt{given}s inside the scope of the method or function they are declared in.
%
This makes the following snippet valid Scala code:
%
\begin{lstlisting}[frame=single, language=scala]
def nPrintBoth(x: Any, y: Any)(n: Int)(using Printer): Unit =
  (1 to n).foreach(_ => printBoth(x, y))
\end{lstlisting}
%
Also note that Scala 3 lets the developer omit \texttt{using} parameters names, since most of the times they are in turn passed downstream implicitly.
%
In those cases, they are accessible through the \texttt{summon[T]} method, which finds the given instance of type \texttt{T} available in the current context.

\subsection{Extension methods}
\label{sec:extension-methods}

Scala 3 introduced extension methods following the same principles that inspired the \texttt{given}/\texttt{using} keywords, that is the overloaded meaning of the \texttt{implicit} keyword.
%
In fact, prior to this version, extension methods were also written using that keyword, in particular by using \texttt{implicit class}es.
%
The following listing shows how it was done:
%
\begin{lstlisting}[frame=single, language=scala]
object Extensions {
  implicit class RichInt(x: Int) {
    def isDivisibleBy(other: Int): Boolean = x % other == 0
  }
}

import Extensions._
println(10.isDivisibleBy(5))
\end{lstlisting}
%
Other than the use of an overloaded keyword, this approach had the disadvantage of having to come up with a name for the implicit class, that would however never be referenced again afterwards.

Scala 3 solved this issue by adding the \texttt{extension} keyword.
%
The previous code, re-written in Scala 3, would be as follows:
%
\begin{lstlisting}[frame=single, language=scala]
object Extensions:
  extension (x: Int)
    def isDivisibleBy(other: Int): Boolean = x % other == 0

import Extensions._
println(10.isDivisibleBy(5))
\end{lstlisting}

\subsection{Context functions}
\label{sec:context-functions}

\textit{Context functions} are a completely new feature of Scala 3, allowing developers to create function types that only accept \textit{context parameters}.

A context function type is written as
\begin{verbatim}
(T1, ..., Tn) ?=> U
\end{verbatim}
which represents a function accepting \texttt{n} context arguments with types \texttt{(T1, ..., Tn)} and returning a value of type \texttt{U}.
%
Context functions can be used just as normal functions, but they have special syntax for passing and getting arguments implicitly.

Consider the following snippet:
%
\begin{lstlisting}[frame=single, language=scala]
given world: String = "World"

def greet(how: String ?=> String): Unit = println(how)
// def greet(how: String ?=> String): Unit = println(how(using world))

// The following lines are equivalent.
greet(s"Hello ${summon[String]}")
greet(who ?=> s"Hello $who")
\end{lstlisting}
%
Here \texttt{greet()} is a method accepting a context function whose context parameter is of type \texttt{String} and also returns a \texttt{String}.
%
Note that the implementation of \texttt{greet()} invokes \texttt{how} by letting the compiler synthesize its argument implicitly, using the \texttt{given String} declared at the top of the snippet.
%
Moreover, both invocations of \texttt{greet()} are equivalent since Scala expands the first expression to a context function literal behind the scenes.

In general, if an expression \texttt{E} is expected to have a context function type \texttt{(T1, ..., Tn) ?=> U} and it is not already a context function literal, it is re-written as \texttt{(x1: T1, ..., xn: Tn) ?=> E} automatically by the compiler.
%
Also, while type-checking \texttt{E}, its arguments are available as givens, which means that they are accessible using \texttt{summon[T]}.

\section{Aggregate computing}

\textit{Aggregate computing} is an emerging approach to the engineering of complex coordination for distributed systems, in particular \textit{Collective Adaptive Systems} \cite{VIROLI2019100486}.
%
It is mostly based on the idea that it is simpler to view system interactions in terms of information propagating through collectives of devices, rather than in terms of individual devices and their interaction with their peers and environment.

Aggregate computing fits particularly well when the nature of the problem requires to deal with a \textit{network of devices} with these features:
%
\begin{itemize}
  \item \textbf{openness}, meaning that the environment in which devices are immersed can exhibit unexpected changes and faults;
  \item \textbf{large scale}, with a possibly huge number of devices/agents that need to coordinate and require good abstractions to be managed;
  \item \textbf{intrinsic adaptiveness}, that is, the ability to react to relevant events in order to guarantee overall system resilience.
\end{itemize}
%
These concerns call for an approach based on \textit{self-organization}, where global and robust coordination behavior emerges from local coordination abstractions.

Another goal of aggregate computing is to give developers a way to describe the behavior of distributed systems with the features described above in a \textit{composable} and \textit{declarative} fashion, in order to scale well with the complexity of the domain.
%
This is possible thanks to the \textit{mathematical core} of aggregate computing, that is based on \textit{computational fields} (see \Cref{sec:ac-abstractions}) and \textit{field calculus} (see \Cref{sec:field-calculus}).

\subsection{Basic abstractions}
\label{sec:ac-abstractions}

Aggregate computing models a distributed system as a set $\mathcal{D}$ of devices, ranged over by $\delta$.
%
On top of that, a reflexive~\footnote{each device is a neighbor of itself.} \textit{neighboring relation} indicates the devices with which one can communicate (which is application-dependent, and can be used to describe logical or physical proximity).
%
In addition, each device has a set of \textit{sensors} that enable the perception of the environment.

The primary abstraction introduced by aggregate computing is the \textit{computational field} (or simply \textit{field}), which is a function $\phi : \mathcal{D} \mapsto \mathcal{L}$ mapping each device $\delta \in \mathcal{D}$ to a local value $l \in \mathcal{L}$ \cite{10.1145/3177774}.
%
A \textit{field evolution} is a dynamically changing field, and a \textit{field computation} takes field evolutions as inputs and produces field evolutions as outputs.
%
These outputs are defined in such a way that they change tracking input changes.

The key idea of aggregate computing is that any field computation (\textit{global interpretation}) can be mapped to a \textit{single-device behavior} that is iteratively executed by all the devices in the network (\textit{local interpretation}).
%
Each iteration executed by a device is called a \textit{computation round} and can be subdivided in three steps:
%
\begin{itemize}
    \item \textbf{sense}: the device gathers information coming from its neighbors and local sensors, which are collected to create its \textit{local context} (or \textit{local state}) for the current round;
    \item \textbf{eval}: the computation defined by the behavior is evaluated against the local context, producing an \textit{export};
    \item \textbf{broadcast}: the export is broadcast to all the device's neighbors, which in turn collect and use this information in their own future rounds.
\end{itemize}

\subsection{Field calculus}
\label{sec:field-calculus}

Field calculus represents a simple language that can be used to describe computations acting on fields.
%
While its syntax, typing, and semantics are deeply discussed in \cite{VIROLI2019100486} and are omitted here for simplicity, a brief description of its elements is presented below:
%
\begin{itemize}
    \item a \textit{field calculus program} $\texttt{P}$ consists of a sequence of \textit{function declarations} $\bar{\texttt{F}}$ followed by the \textit{main expression} $\texttt{e}$;
    \item an expression $\texttt{e}$ can be:
    \begin{itemize}
        \item a \textit{variable} $\texttt{x}$ (e.g., function parameters, \dots);
        \item a \textit{local value} $l$ (e.g., booleans, numbers, strings, tuples, \dots);
        \item a \textit{neighboring field value} $\phi$, i.e., a (per-device) mapping from the devices's neighbors to local values;
        \item a \textit{function call} $\texttt{f}(\bar{\texttt{e}})$ to a \textit{user-declared function} or a \textit{built-in function} (e.g., maths or boolean operators, sensors, \dots);
        \item a \textit{branching expression} $\texttt{if} (\texttt{e}_1)\{\texttt{e}_2\}\{\texttt{e}_3\}$ which splits computation into isolated sub-regions, resulting in $\texttt{e}_2$ where and when $\texttt{e}_1$ evaluates to true, and in $\texttt{e}_3$ otherwise;
        \item a $\texttt{nbr}(\texttt{e})$ construct, which creates a neighboring field value that maps each neighbor to the latest result of evaluating $\texttt{e}$;
        \item a $\texttt{rep}(\texttt{e}_1)\{(\texttt{x})\Rightarrow \texttt{e}_2\}$ construct, which models state evolution over time.
    \end{itemize}
\end{itemize}

To work properly, the semantics of \texttt{nbr} and \texttt{rep} require a way to access, respectively, the last registered state of each neighbor and the last registered output of the device itself.
%
In addition, this process should be made in such a way that different instances of \texttt{rep} and \texttt{nbr} cannot inadvertently \quotes{swap} their respective value.
%
This process is called \textit{alignment}, and it has the consequence that two branches of an \texttt{if} expression execute in isolation, meaning that two devices that execute different branches cannot communicate with each other inside their branches.
%
In practice, this process is done by carefully constructing the export of an expression as an \textit{evaluation tree} that represents the aggregate computation.
%
The complete semantics of export construction and alignment can be found in Appendix C of \cite{10.1145/3177774}.

\section{Functional reactive programming}
\label{sec:frp}

\textit{Functional Reactive Programming} (FRP) is a style of programming that unifies the approaches of \textit{Reactive Programming} (RP) and \textit{Functional Programming} (FP, see \Cref{sec:fp}) to tame the complexity of \textit{event-driven interactive applications}.

The following sections describe the conceptual evolution of the paradigms used to deal with event-driven scenarios, starting from the traditional \textit{observer pattern} and evolving into \textit{FRP}.
%
The discussion is primarily based on the book \cite{blackheath2016functional} and on the \textbf{Sodium} library written by the authors of the book (see \Cref{sec:sodium} for further details).

\subsection{Limitations of the observer pattern}
\label{sec:observer}

The observer pattern is a way to define event-driven logic by registering \textit{callbacks} (or \textit{listeners}) to the sources of events, creating a one-to-many dependency from the producer of events to its consumers.
%
This is the traditional (and mainstream) approach to dealing with stateful, event-driven logic, which is typically associated with applications like GUIs or games.

Typically, the observer pattern is associated to some \textit{state machine} that implements the \textit{domain logic} while encapsulating the application \textit{state}.
%
This model can be described as follows:
%
\begin{itemize}
    \item an event gets pushed to the listener;
    \item the listener activates the logic based on the input event and on the current state;
    \item the logic updates the current state;
    \item the logic may produce some output that is not fed back into the state.
\end{itemize}

While the observer pattern can be pretty straightforward for simple enough scenarios, the growing complexity of modern event-driven applications brings to light some of its shortcomings, which are called by the book \quotes{the six plagues of listeners}:
%
\begin{itemize}
    \item \textit{unpredictable order}: since listeners are typically notified in the order they are registered in, keeping track of the temporal dependencies between listeners can become infeasible and lead to unpredictable behavior;
    \item \textit{missed first event}: it can be difficult to guarantee that listeners are registered before the first event is sent;
    \item \textit{messy state}: traditional state machines are hard to reason about and tend to quickly grow in complexity;
    \item \textit{threading issues}: using locks inside listeners to guarantee thread safety can lead to deadlocks which are difficult to track down;
    \item \textit{leaking callbacks}: forgetting to unregister a listener can cause memory leaks;
    \item \textit{accidental recursion}: the order in which state is updated and listeners are notified is crucial and needs careful attention.
\end{itemize}

\subsection{FRP paradigm}
\label{sec:frp-paradigm}

In order to overcome the limitations of the observer pattern, FRP proposes a paradigm shift built around the notion of \textit{continuous time-varying values} and \textit{propagation of change} \cite{bainomugisha2013survey}.
%
This shift allows for a more \textit{declarative} way of writing programs, since developers only have to describe them in terms of what they do and let the underlying execution model manage when changes should be propagated.
%
In fact, RP promotes the idea of a \textit{dependency graph of values and computation}, that dictates the flow of data and the propagation of changes occurring to each node of the graph.

According to the terminology used in Sodium (see \Cref{sec:sodium}), the dependency graph is composed of:
%
\begin{itemize}
  \item \textit{cells}, representing values that change over time (possibly in a continuous fashion);
  \item \textit{streams}, representing sequences of discrete events.
\end{itemize}
%
Cells are typically used to represent state and its evolution over time, while streams encode the occurrence of events of interest upon which state should change or actions should be taken.

FRP provides operators to transform and combine cells and streams and obtain new ones, mainly by \textit{mapping}, \textit{filtering}, \textit{merging} or \textit{converting one into the other}.
%
Since there is no standard specification of what these operators should be, they are best explained by referring to Sodium's API and underlying model in \Cref{sec:sodium}.
%
These operators are generally used upon startup to construct the dependency graph.
%
This is known as the \textit{initialization} stage.
%
After initialization, the FRP engine takes care of taking inputs and converting it into outputs that act upon external consumers (\textit{running} stage).

\subsection{FRP in Sodium}
\label{sec:sodium}

Sodium~\footnote{\url{https://github.com/SodiumFRP/sodium}} is a library designed to work with FRP and written by the authors of \cite{blackheath2016functional}.
%
Despite being mainly developed for Java, it also has a variety of adaptations for other languages, including C\#, F\# and Scala.
%
However, these adaptations do not always implement all the features that are included in the Java version.
%
For this reason, the remainder of this section presents code snippets that are written in Java.

As stated before, Sodium is primarily based on two types:
%
\begin{itemize}
  \item \texttt{Cell<T>} represents a value of type \texttt{T} that changes over time;
  \item \texttt{Stream<T>} represents a sequence of emissions of events, each holding data of type \texttt{T}.
\end{itemize}
%
In addition, Sodium implements a series of \textit{primitives} that can be used to perform transformations on cells and streams, ultimately defining the domain logic.

The following sections give an overview of the most relevant features of Sodium.

\subsubsection{Core Primitives}

Sodium is based on a set of \textit{ten primitives} that form its \textit{conceptual core}.
%
These primitives are where the functional part of FRP comes in.
%
To guarantee the compositionality~\footnote
{
  The property stating that the meaning of an expression is determined by the meanings of its parts and the rules used to combine them.
  %
  More practically, compositionality gives some guarantees that working subparts will still work when combined together.
}
%
of FRP, all functions passed to the primitives must be referentially transparent.

The ten primitives are described in more detail in the following paragraphs.

\paragraph{Never}
Produces a stream that will never emit any events.
%
\begin{lstlisting}[frame=single, language=java]
Stream<String> never = new Stream<>();
\end{lstlisting}
%
Sodium does not provide a specific \texttt{never} method, but uses the empty constructor of the \texttt{Stream<T>} class as a way to create the \textit{never} stream.

\paragraph{Constant}
Produces a constant cell that will always have the given value.
%
\begin{lstlisting}[frame=single, language=java]
Cell<String> helloWorld = new Cell<>("Hello World!");
\end{lstlisting}
%
Just like \textit{never}, there is no method named \textit{constant}, but the constructor of \texttt{Cell<T>} accepting a \texttt{T} creates a constant cell.

\paragraph{Map (stream)}
Produces a stream emitting the events emitted by the source stream after applying a mapping function.
%
\begin{lstlisting}[frame=single, language=java]
Stream<Integer> source = ...;
Stream<String> out = source.map(x -> Integer.toString(x));
\end{lstlisting}  

\paragraph{Map (cell)}
Produces a cell whose value is taken from the source cell by applying a mapping function.
%
\begin{lstlisting}[frame=single, language=java]
Cell<Integer> source = ...;
Cell<String> out = source.map(x -> Integer.toString(x));
\end{lstlisting}

\paragraph{Merge}
Combines two streams of the same type together, returning a stream that emits events from either input.
%
Since Sodium supports \textit{simultaneous events} (see \Cref{sec:transactions} for more details), if both input streams happen to emit at the same time the given combining function will be used to produce the final output event.
%
\begin{lstlisting}[frame=single, language=java]
Stream<Integer> left = ...;
Stream<Integer> right = ...;
Stream<Integer> merged = left.merge(right, (l, r) -> l + r);
\end{lstlisting}

\paragraph{Hold}
Converts a stream into a cell in such a way that the cell's value is that of the most recent event received.
%
The initial value for the cell (before the first event is emitted by the stream) is the argument passed to \texttt{hold()}.
%
\begin{lstlisting}[frame=single, language=java]
Stream<Integer> events = ...;
Cell<Integer> hold = events.hold(0);
\end{lstlisting}

\paragraph{Snapshot}
Captures the value of the given cell whenever the source stream fires.
%
Produces a stream firing at the same time as the source stream and emitting combinations of the values from the stream and the cell using the supplied function.
%
\begin{lstlisting}[frame=single, language=java]
Stream<String> trigger = ...;
Cell<Integer> state = ...;
Stream<String> out = trigger.snapshot(state, (t, s) -> t + s);
\end{lstlisting}

\paragraph{Filter}
Produces a stream that emits the events from the source stream only if the pass the given predicate.
%
\begin{lstlisting}[frame=single, language=java]
Stream<Integer> events = ...;
Stream<Integer> out = events.filter(x -> x > 0);
\end{lstlisting}

\paragraph{Lift}
Combines two or more cells into one by combining the values of all input cells using a combining function.
%
\begin{lstlisting}[frame=single, language=java]
Cell<Integer> left = ...;
Cell<Integer> right = ...;
Cell<Integer> out = left.lift(right, (l, r) -> l + r);
\end{lstlisting}

\paragraph{Sample}
Returns the current value of the cell it is invoked on.
%
\begin{lstlisting}[frame=single, language=java]
Cell<String> state = ...;
String currentState = state.sample();
\end{lstlisting}
  
\paragraph{Switch (stream)}
Flattens a cell of streams into a single stream that emits whenever the active stream for the cell emits.
%
\begin{lstlisting}[frame=single, language=java]
Cell<Stream<Integer>> source = ...;
Stream<Integer> out = Cell.switchS(source);
\end{lstlisting}

\paragraph{Switch (cell)}
Flattens a cell of cells into a single cell whose value is the value of the active cell of the wrapper cell.
\begin{lstlisting}[frame=single, language=java]
Cell<Cell<Integer>> source = ...;
Cell<Integer> out = Cell.switchC(source);
\end{lstlisting}

\subsubsection{External interfacing}

The \textit{pure core} of Sodium is not enough to deal with all the requirements of an event-driven application.
%
In fact, these requirements include I/O (e.g., network communication, interfacing with the file system, \dots), GUIs, and other concerns that are typically not integrated with Sodium.
%
This requires a way for developers to interface the pure core with the \textit{impure} nature of external concerns, namely:
%
\begin{itemize}
    \item \textit{pushing events into streams and cells};
    \item \textit{listening to events from streams and cells}.
\end{itemize}
%
These somewhat resemble the mechanisms used by the observer pattern (recall \Cref{sec:observer}), but they have special constraints and rules to keep compositionality intact, especially when working with transactions (see \Cref{sec:transactions}).

\paragraph{Pushing events into streams and cells}
Sodium comes with subclasses of \texttt{Stream<T>} and \texttt{Cell<T>} that expose a \texttt{send()} method allowing events and values to be pushed into the FRP logic.
%
These are, respectively, \texttt{StreamSink<T>} and \texttt{CellSink<T>}.
%
The idea is that a module that deals with an external concern would use these sinks internally to push data into the FRP logic, and only expose those as their \quotes{pure} counterparts.

The following listing shows an example of how to turn a Swing \texttt{JButton} into a stream of its clicks.
%
\begin{lstlisting}[frame=single, language=java]
public Stream<Unit> clicks(JButton button) {
    StreamSink<Unit> clicksSink = new StreamSink<>();
    button.addActionListener(e -> clicksSink.send(Unit.UNIT));
    return clicksSink;
}
\end{lstlisting}

\paragraph{Listening to events from streams and cells}
The values of streams and cells can be made available to the rest of the application by \textit{listening} to their updates.
%
To do this, \texttt{Stream<T>} and \texttt{Cell<T>} have a \texttt{listen()} method to register a listener that gets notified whenever that stream fires or the value of the cell is updated.
%
\begin{lstlisting}[frame=single, language=java]
public <X> void printAll(Stream<X> stream) {
    stream.listen(x -> System.out.println("Emitted: " + x));
}
\end{lstlisting}

\subsubsection{Transactions}
\label{sec:transactions}

Most FRP systems support the idea that multiple events can be \textit{simultaneous}.
%
This can be done by defining a boundary (which is called a \textit{transaction} in Sodium) in which every event is considered to be happening at the same time.
%
Naturally, FRP primitive should be designed to take this aspect into account, and provide a way to handle simultaneous events correctly (recall the \textit{merge} primitive for example).
%
All Sodium primitives are automatically run inside transactions, but developers can manually define transactions using \texttt{Transaction.run(() -> ...)} or \texttt{Transaction.runVoid(() -> ...)}.

Transactions can be used primarily for two reasons:
%
\begin{itemize}
    \item wrapping the construction of the dependency graph in a single instance to avoid the \textit{missed first event} plague;
    \item using \texttt{Sink}s to send multiple events that should be considered simultaneous.
\end{itemize}

\subsubsection{Looping streams and cells}

In FRP there's often the need to have the definition of a cell or of a stream depend on itself.
%
Since programming languages (like Java in this case) do not typically allow references to variables before their declaration, Sodium provides a mechanism that simulates \textit{forward references}~\footnote{Referencing an identifier that has not been declared yet.}.
%
These are \texttt{CellLoop<T>} and \texttt{StreamLoop<T>}.
%
The idea is that these classes are, respectively, subclasses of \texttt{Cell<T>} and \texttt{Stream<T>} that can act as placeholders for cells and streams before their initialization, and that can be freely used as their counterparts.
%
After all the dependencies have been setup and the real value for the placeholders can be initialized, this can be done by calling the \texttt{loop()} method.

An example where looping is necessary could be an accumulator, which consists of a cell whose value is the sum over time of values emitted by a stream.
%
\begin{lstlisting}[frame=single, language=java]
public Cell<Integer> accumulate(Stream<Integer> deltas) {
    return Transaction.run(() -> {
        CellLoop<Integer> output = new CellLoop<>();
        Stream<Integer> updates = deltas.snapshot(output, (c, d) -> c + d);
        output.loop(updates.hold(0));
        return output;
    });
}
\end{lstlisting}
%
It is worth noting that looping will fail with an exception if it is not wrapped inside a transaction, in order to avoid updates coming before the call to \texttt{loop()}.
