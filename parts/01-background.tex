\chapter{Background}
\label{chap:background}

This chapter gives an high level overview of the concepts, paradigms, and frameworks that were used as references throughout the development of this thesis.

\section{Functional programming}
\label{sec:fp}

\textit{Functional Programming} is a programming paradigm in which computation is expressed as a transformation of inputs into outputs using functions and function composition.
%
Here, functions are to be intended in the \textit{mathematical} sense of the term, meaning that they are just mappings from elements of their domain to elements of their co-domain.

\subsection{Functional programming concepts}

This section illustrates some of the key concepts on which functional programming is based upon and that are key when working in a functional style.

\paragraph{Purity}

The mathematical definition of a function can be adapted to the context of computer programming, in which mathematical functions are referred to as \textbf{pure functions}.
%
To be pure, a function must satisfy the following properties:
%
\begin{itemize}
    \item given the same arguments, it always returns the same value, or in other words, its output depends solely on its arguments;
    \item it must produce no observable side effects (e.g. mutate global shared state, send data over output streams, etc).
\end{itemize}

% TODO: show some examples (both positive and negative) (maybe in pseudo-code?)

\paragraph{Referential transparency}

A sub-expression (i.e. the application of a function) is said to be \textit{referentially transparent} if it can be safely substituted with its final value without changing the overall semantics of the complete expression that contains it.
%
This is a direct consequence of function purity, since a pure function's only observable effect is the value it returns for its given arguments and that value is consistent over time.
%
Due to this fact, referential transparency and purity are often used (erroneously) as synonyms.
%
While it is true that purity implies referential transparency, the opposite is not, in general.

\paragraph{Evaluation order strategies}

Functional languages typically support different ways to evaluate arguments as they are passed to functions.
%
There are three main approaches:
%
\begin{itemize}
    \item \textit{call-by-value}: arguments are evaluated before the function application;
    \item \textit{call-by-name}: arguments are evaluated each time they're value is required inside the body of the function;
    \item \textit{call-by-need}: also referred to as \textit{lazy} evaluation, arguments are evaluated once the first time their value is needed inside the body of the function.
\end{itemize}

\paragraph{Immutability}

One of the consequences of purity when writing code in a functional style is that programs are not allowed to have any global state that is shared among their sub-components.
%
This also means that the data structures to be used must be designed accordingly and should therefore be \textit{immutable}, allowing state changes only via creating new versions of the same data structure.
%
This is typically not a problem, since complex data structures (e.g. collections like lists, sets, maps, \dots) are optimized to reuse as much as possible when creating copies of themselves.

\paragraph{Higher order functions}

Functional programming proposes the idea of \textit{functions as first-class citizens}, indicating that functions can also be considered values and be passed around just like traditional values.
%
Therefore a function can take functions as arguments or return functions as outputs, in which case is called an \textit{higher order function}.

% TODO: add a section for compositionality.

\section{Scala 3}

Scala is a programming language built on top of the Java Virtual Machine (JVM), with support for both the \textit{object-oriented} and the \textit{functional} paradigms \cite{scala-lang-spec}, effectively making it a \textit{multi-paradigm language}.
%
It is a pure object-oriented language, in fact everything is an \textit{object} and objects are defined through \textit{classes} and \textit{traits}.
%
It is a functional language, because it supports the idea of functions as values and allows higher order functions to be defined.

The main features of Scala are:
%
\begin{itemize}
    \item support for both OOP and FP;
    \item seamless integration with the Java ecosystem and the JVM;
    \item powerful static type system;
    \item flexible syntax that makes it a scalable language;
\end{itemize}

The most recent version of Scala (at the time of writing) is Scala 3 \cite{scala3-reference}, which is the version that has been used during development.
%
Scala 3 introduces several new constructs and improvements over its predecessor \cite{new-in-scala-3}, that were considered to be necessary to streamline the development process and allow for a concise and conveying syntax.
%
The most relevant that were also used for this project can be summarized as follows:
%
\begin{itemize}
    \item \textbf{optional braces} introduce the ability to use a python-like syntax that controls scopes through indentation;
    \item \textbf{enumerations} improve on the traditional way of defining \textit{algebraic data types} (see \Cref{sec:enums}) that required the use of \texttt{sealed trait}s;
    \item \textbf{improved contextual abstractions} replace the use of the old \texttt{implicit}s with new constructs that better convey the developer's intent, in particular:
    \begin{itemize}
        \item \texttt{using} clauses allow methods to abstract over information that is available in the calling context and that should be passed implicitly (see \Cref{sec:given-using});
        \item \texttt{given} instances define canonical values for types that can be passed implicitly (see \Cref{sec:given-using}) and are typically used to define \textit{type class instances};
        \item \texttt{extension} methods allow developers to attach methods to types after their definition (see \Cref{sec:extension-methods});
        \item implicit conversions let the compiler view a type as another and perform conversions without explicit casting;
        \item context functions define types of functions that only take context parameters (see \Cref{sec:context-functions});
    \end{itemize}
\end{itemize}

The following sections give more details on these constructs.

\subsection{Enumerations and algebraic data types}
\label{sec:enums}

An algebraic data type (ADT) is a structured type defined as a composition of other types, which can in turn be other ADTs or atomic types.
%
ADTs can belong to one of these categories:
%
\begin{itemize}
    \item \textbf{Product Types} (also known as \textit{records}): defined as the cartesian product of its composing types;
    \item \textbf{Sum Types} (also known as \textit{discriminated unions}): defined as the union of its composing types.
\end{itemize}
%
As an example, let's consider modeling a binary tree.
%
A binary tree can be represented as an ADT through a sum type (\texttt{Tree}), which is a discriminated union of these product types:
%
\begin{itemize}
    \item \texttt{Leaf(x)}, where \texttt{x} is the value contained in the leaf itself;
    \item \texttt{Node(x, left, right)} where x is the value contained in the node itself, and \texttt{left} and \texttt{right} are respectively the left and right subtrees.
\end{itemize}
%
This ADT indicates that a binary tree is either a \textit{leaf}, in which case it only stores the value it contains, or a \textit{node}, in which case it stores its value a the left and right subtrees.
%
Note that this is a recursive definition, since \texttt{left} and \texttt{right} are also of type \texttt{Tree}.

In Scala 2, an ADT could be defined using \texttt{sealed trait}s (to represent sum types) in combination with \texttt{case class}es (modeling product types).
%
Note the use of the \texttt{sealed} keyword, which guarantees that a trait decorated with this modifier will not be extended in other source files other than the one where the trait is declared.
%
This is fundamental, since a discriminated union should not be open to extension and allow only its composing types to be used.
%
In addition, \texttt{case classes} are a perfect candidate to represent product types due to their structure (resembling that of records) and can be used seamlessly with \textit{pattern matching}.

In Scala 2, the binary tree example would be implemented as follows:
%
\begin{lstlisting}[frame=single, language=scala]
sealed trait Tree[T]
case class Leaf[T](x: T) extends Tree[T]
case class Node[T](x: T, left: Tree[T], right: Tree[T]) extends Tree[T]
\end{lstlisting}

Scala 3 takes an approach to ADTs that better conveys the intent of the developer, offering a structure that is specifically designed to represent discriminated unions.
%
The new version introduces the \texttt{enum} keyword, which smooths out the process of defining discriminated unions.
%
The Scala 3 version of the binary tree example becomes
%
\begin{lstlisting}[frame=single, language=scala]
enum Tree[T]:
  case Leaf(x: T)
  case Node(x: T, left: Tree[T], right: Tree[T])
\end{lstlisting}
%
which is more succinct and avoids the noise required by its predecessor.

Finally, both approaches are well suited to be used with pattern matching (although only Scala 3 is shown here).
%
This example show the implementation of a method that converts a binary tree to a string, by using \textit{preorder traversal}.
%
\begin{lstlisting}[frame=single, language=scala]
import Tree._

def stringify[T](tree: Tree[T]): String = tree match
  case Leaf(x) => x.toString
  case Node(x, l, r) => s"$x[${stringify(l)},${stringify(r)}]"

val aTree = Node(
  1,
  Node(
    2,
    Leaf(3),
    Leaf(4)
  ),
  Leaf(5)
)

println(stringify(aTree)) // 1[2[3,4],5]
\end{lstlisting}

\subsection{Using clauses and given instances}
\label{sec:given-using}

The \texttt{using} and \texttt{given} keywords were introduced in Scala 3 as a replacement for the \texttt{implicit} keyword when passing \textit{context parameters} and when defining \textit{canonical values}.
%
Before Scala 3, in fact, the \texttt{implicit} mechanism lacked on clarity of intent, since the keyword was also used to define extension methods (see \Cref{sec:extension-methods}) and implicit conversions.

The following snippet shows how \texttt{implicit}s worked before Scala 3.
%
First, a developer would need a method accepting a parameter \texttt{implicit}ly.
%
Here, the \texttt{printBoth()} method accepts a \texttt{printer} argument that should be inferred from the caller context and not be passed explicitly.
%
\begin{lstlisting}[frame=single, language=scala]
trait Printer {
  def print(x: Any): Unit
}

def printBoth(x: Any, y: Any)(implicit printer: Printer): Unit = {
  printer.print(x)
  printer.print(y)
}
\end{lstlisting}

Next, when calling the \texttt{printBoth()} method, Scala tries to synthesize an appropriate value of type \texttt{Printer} that is marked as \texttt{implicit} in the calling scope:
%
\begin{lstlisting}[frame=single, language=scala]
implicit val printer: Printer = x => println(x)

// The following lines are equivalent.
printBoth("A", "B")
printBoth("A", "B")(printer)
\end{lstlisting}
%
Note that the \texttt{printer} value is declared using the \texttt{implicit} keyword, marking it as suitable to be passed implicitly.

As stated at the beginning of this section, Scala 3 replaces the \texttt{implicit} keyword with \texttt{using} and \texttt{given}.
%
Other than that, not very much changes in the structure of the previous code:
%
\begin{lstlisting}[frame=single, language=scala]
trait Printer:
  def print(x: Any): Unit

def printBoth(x: Any, y: Any)(using printer: Printer): Unit =
  printer.print(x)
  printer.print(y)

...

given printer: Printer = x => println(x)

// The following lines are equivalent.
printBoth("A", "B")
printBoth("A", "B")(using printer)
\end{lstlisting}

Note that, just like \texttt{implicit} parameters, \texttt{using} parameters are available as \texttt{given}s inside the scope of the method or function they are declared in.
%
This makes the following snippet valid Scala code:
%
\begin{lstlisting}[frame=single, language=scala]
def nPrintBoth(x: Any, y: Any)(n: Int)(using Printer): Unit =
  (1 to n).foreach(_ => printBoth(x, y))
\end{lstlisting}
%
Also note that Scala 3 lets the developer omit \texttt{using} parameters names, since most of the times they are in turn passed downstream implicitly.
%
In those cases, they are accessible through the \texttt{summon[T]} method, which finds the given instance of type \texttt{T} available in the current context.

\subsection{Extension methods}
\label{sec:extension-methods}

Scala 3 introduced extension methods following the same principles that inspired the \texttt{given}/\texttt{using} keywords, that is the overloaded meaning of the \texttt{implicit} keyword.
%
In fact, prior to this version extension methods were also written using that keyword, in particular by using \texttt{implicit class}es.
%
The following listing shows how it was done:
%
\begin{lstlisting}[frame=single, language=scala]
object Extensions {
  implicit class RichInt(x: Int) {
    def isDivisibleBy(other: Int): Boolean = x % other == 0
  }
}

import Extensions._
println(10.isDivisibleBy(5))
\end{lstlisting}
%
Other than the use of an overloaded keyword, this approach had the disadvantage of having to come up with a name for the implicit class, that would however never be referenced again afterwards.

Scala 3 solved this issue by adding the \texttt{extension} keyword.
%
The previous code, re-written in Scala 3, would be as follows:
%
\begin{lstlisting}[frame=single, language=scala]
object Extensions:
  extension (x: Int)
    def isDivisibleBy(other: Int): Boolean = x % other == 0

import Extensions._
println(10.isDivisibleBy(5))
\end{lstlisting}

\subsection{Context functions}
\label{sec:context-functions}

\textit{Context functions} are a completely new feature of Scala 3, allowing developers to create function types that only accept \textit{context parameters}.

A context function type is written as
\begin{verbatim}
(T1, ..., Tn) ?=> U
\end{verbatim}
which represents a function accepting \texttt{n} context arguments with types \texttt{(T1, ..., Tn)} and returning a value of type \texttt{U}.
%
Context functions can be used just as normal functions, but they have special syntax for passing and getting arguments implicitly.

Consider the following snippet:
%
\begin{lstlisting}[frame=single, language=scala]
given world: String = "World"

def greet(how: String ?=> String): Unit = println(how)
// def greet(how: String ?=> String): Unit = println(how(using world))

// The following lines are equivalent.
greet(s"Hello ${summon[String]}")
greet(who ?=> s"Hello $who")
\end{lstlisting}
%
Here \texttt{greet()} is a method accepting a context function whose context parameter is of type \texttt{String} and also returns a \texttt{String}.
%
Note that the implementation of \texttt{greet()} invokes \texttt{how} by letting the compiler synthesize its argument implicitly, using the \texttt{given String} declared at the top of the snippet.
%
Moreover, both invocations of \texttt{greet()} are equivalent since Scala expands the first expression to a context function literal behind the scenes.

In general, if an expression \texttt{E} is expected to have a context function type \texttt{(T1, ..., Tn) ?=> U} and it is not already a context function literal, it is re-written as \texttt{(x1: T1, ..., xn: Tn) ?=> E} automatically by the compiler.
%
Also, while type-checking \texttt{E}, its arguments are available as givens, which means that they are accessible using \texttt{summon[T]}.

\section{Aggregate computing}

\subsection{ScaFi}

\section{Functional reactive programming}

\textit{Functional Reactive Programming} (FRP) is a style of programming that unifies the approaches of \textit{Reactive Programming} (RP, see \Cref{sec:rp}) and \textit{Functional Programming} (FP, see \Cref{sec:fp}) to tame the complexity of \textit{event-driven interactive applications}.
%
More precisely, it is an improvement over RP that takes concepts from FP to add certain guarantees on top of it.
%
In particular, the most important principle borrowed from FP is \textit{compositionality}, since FRP is built on top of the idea that the nature of the parts doesn't change when composing them.
%
This is further explained in \Cref{sec:rp-to-frp}.

The following sections describe the conceptual evolution of the paradigms used to deal with event-driven scenarios, starting from the traditional \textit{observer pattern} evolving first into \textit{RP} and then into \textit{FRP}.
%
The discussion is primarily based on the book \cite{blackheath2016functional} and on the \textbf{Sodium} library written by the authors of the book (see \Cref{sec:sodium} for further details).

\subsection{Limitations of the observer pattern}

The observer pattern is a way to define event-driven logic by registering \textit{callbacks} (or \textit{listeners}) to the sources of events, creating a one-to-many dependency from the producer of events to its consumers.
%
This is the traditional (and mainstream) approach to dealing with stateful, event-driven logic, which is typically associated with applications like GUIs or games.

Typically, the observer pattern is associated to some \textit{state machine} that implements the \textit{domain logic} while encapsulating the application \textit{state}.
%
This model can be described as follows:
%
\begin{itemize}
    \item an event gets pushed to the listener;
    \item the listener activates the logic based on the input event and on the current state;
    \item the logic updates the current state;
    \item the logic may produce some output that is not fed back into the state.
\end{itemize}

While the observer pattern can be pretty straightforward for simple enough scenarios, the growing complexity of modern event-driven applications brings to light some of its shortcomings, which are called by the book \quotes{the six plagues of listeners}:
%
\begin{itemize}
    \item \textit{unpredictable order}: since listeners are typically notified in the order they are registered in, keeping track of the temporal dependencies between listeners can become infeasible and lead to unpredictable behavior;
    \item \textit{missed first event}: it can be difficult to guarantee that listeners are registered before the first event is sent;
    \item \textit{messy state}: traditional state machines are hard to reason about and tend to quickly grow in complexity;
    \item \textit{threading issues}: using locks inside listeners to guarantee thread safety can lead to deadlocks which are difficult to track down;
    \item \textit{leaking callbacks}: forgetting to unregister a listener can cause memory leaks;
    \item \textit{accidental recursion}: the order in which state is updated and listeners are notified is crucial and needs careful attention.
\end{itemize}

While basic RP is enough to deal with some of the \quotes{plagues} described above, the additional benefits introduced by FRP are necessary to completely banish these limitations during development.

\subsection{Reactive Programming}
\label{sec:rp}

% paradigm description
% application life cycle
% models (push/pull)

\subsection{From RP to FRP}
\label{sec:rp-to-frp}

\subsection{FRP in Sodium}
\label{sec:sodium}

\subsubsection{Cells vs Streams}

\subsubsection{Core Primitives}

\subsubsection{Operational Primitives}

% time